{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import codecs\n",
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size': 64,\n",
    "    'lr' : 0.001,\n",
    "    'max_sent_len': 20,\n",
    "    'epochs': 500,\n",
    "    'drops' : [0.1]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_dir = '../ner_model_weight/model_conv.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 20, 32)       16000       Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 20, 128)      36864       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pre_intent (Dense)              (None, 55)           7040        global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "pre_ner (Dense)                 (None, 20, 36)       4608        bidirectional[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 64,512\n",
      "Trainable params: 64,512\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(data_path):\n",
    "    \"\"\"\n",
    "    意图识别抽取出label\n",
    "    槽位识别与填充作为命名实体识别问题，对每一个字进行实体标注, ate_time', 'B-target', 'I-date_time', 'I-date_time', 'I-operation', 'I-date_time', 'I-date_time']\n",
    "[ ]:\n",
    "￼\n",
    "​B E I O S\n",
    "    \"\"\"\n",
    "    with codecs.open(data_path,\"r\",encoding=\"utf-8\") as fp:\n",
    "        data = json.load(fp)\n",
    "    texts = [example['text'].replace(\" \",\"\") for example in data]\n",
    "    intent_labels = [example['intent'] for example in data]\n",
    "    \n",
    "    slots_ners = []\n",
    "    count = 0\n",
    "    for example in data:\n",
    "        if 'entities' in example.keys():\n",
    "            text = example['text']\n",
    "            ner = ['O'] * len(text)\n",
    "            slots = example['entities']\n",
    "            for key,val in slots.items():\n",
    "                start_idx = text.find(val)\n",
    "                end_idx = start_idx + len(val) -1\n",
    "                if len(val) == 1:\n",
    "                    ner[start_idx] = 'S-' + key\n",
    "                else:\n",
    "                    ner[start_idx] = 'B-' + key\n",
    "                    ner[end_idx] = 'E-'+ key\n",
    "                    for idx in range(start_idx+1, end_idx):\n",
    "                        ner[idx] = 'I-' + key\n",
    "        else:\n",
    "            text = example['text']\n",
    "            ner = ['O'] * len(text)\n",
    "        slots_ners.append(ner)\n",
    "#     print('texts len: ', len(texts))\n",
    "#     print('intent_lables len: ',len(intent_labels))\n",
    "#     print('slots_ners len: ', len(slots_ners))\n",
    "    return texts, intent_labels, slots_ners  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path =\"../dataset/data_v2.json\"\n",
    "max_sent_len = params[\"max_sent_len\"]\n",
    "texts, intent_labels, slots_ners = extract_data(data_path)\n",
    "\n",
    "train_text = [d for i , d in enumerate(texts) if i % 10 != 0]\n",
    "train_l = len(train_text) // params['batch_size']\n",
    "\n",
    "train_text = train_text[:train_l*params['batch_size']]\n",
    "valid_text = [d for i , d in enumerate(texts) if i % 10 == 0]\n",
    "valid_l = len(valid_text) // params['batch_size']\n",
    "valid_text = valid_text[:valid_l*params['batch_size']]\n",
    "\n",
    "train_intent = [d for i , d in enumerate(intent_labels) if i % 10 != 0]\n",
    "train_intent = train_intent[:train_l*params['batch_size']]\n",
    "valid_intent = [d for i , d in enumerate(intent_labels) if i % 10 == 0]\n",
    "valid_intent = valid_intent[:valid_l*params['batch_size']]\n",
    "\n",
    "train_ner = [d for i , d in enumerate(slots_ners) if i % 10 != 0]\n",
    "train_ner = train_ner[:train_l*params['batch_size']]\n",
    "valid_ner = [d for i , d in enumerate(slots_ners) if i % 10 == 0]\n",
    "valid_ner =valid_ner[:valid_l*params['batch_size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../char_6.17.json', mode='r', encoding='utf-8') as f:\n",
    "    dicts = json.load(f)\n",
    "\n",
    "char2id = dicts['char2id']\n",
    "id2char = dicts['id2char']\n",
    "intent2id = dicts['intent2id']\n",
    "id2intent = dicts['id2intent']\n",
    "slot2id = dicts['slot2id']\n",
    "id2slot = dicts['id2slot']\n",
    "\n",
    "params['intent_num'] = len(intent2id)\n",
    "params['slot_num'] = len(slot2id)\n",
    "params['id2intent'] = id2intent\n",
    "params['id2slot'] = id2slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans2labelid(vocab, labels, max_sent_len):\n",
    "    labels = [vocab[label] for label in labels]\n",
    "    if len(labels) < max_sent_len:\n",
    "        labels += [0] * (max_sent_len - len(labels))\n",
    "    else:\n",
    "        labels = labels[:max_sent_len]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(txt_seqs, intent_labels, slot_ners,char2id,intent2id,slot2id,max_sent_len):\n",
    "    dataset_text_labels = []\n",
    "    dataset_intent_labels = []\n",
    "    dataset_ner_labels = []\n",
    "    \n",
    "    for index in range(len(txt_seqs)):\n",
    "        dataset_text_labels.append(trans2labelid(char2id,txt_seqs[index],max_sent_len))\n",
    "        dataset_intent_labels.append([intent2id[intent_labels[index]]])\n",
    "        dataset_ner_labels.append(trans2labelid(slot2id,slot_ners[index],max_sent_len))\n",
    "    dataset_text_labels = np.array(dataset_text_labels)\n",
    "    dataset_intent_labels = np.array(dataset_intent_labels)\n",
    "    dataset_ner_labels = np.array(dataset_ner_labels)\n",
    "    \n",
    "    return dataset_text_labels, dataset_intent_labels, dataset_ner_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_seq, valid_intent, valid_ner =  read_data(valid_text, valid_intent, valid_ner,char2id,intent2id,slot2id,max_sent_len) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "    for data in tf.data.Dataset.from_tensor_slices(({\n",
    "    \"Input\" : valid_seq\n",
    "    },\n",
    "    {\n",
    "        \"pre_intent\":valid_intent,\n",
    "        \n",
    "        \"pre_ner\":valid_ner\n",
    "    })).batch(1).take(100):\n",
    "        yield [tf.dtypes.cast(data, tf.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpph6l8_97/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpph6l8_97/assets\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to parse the model: pybind11::init(): factory function returned nullptr.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.7/site-packages/tensorflow/lite/python/optimize/calibrator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_content)\u001b[0m\n\u001b[1;32m     51\u001b[0m       self._calibrator = (\n\u001b[0;32m---> 52\u001b[0;31m           _calibration_wrapper.CalibrationWrapper(model_content))\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: pybind11::init(): factory function returned nullptr",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-31def4e2631f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupported_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpsSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLITE_BUILTINS_INT8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Set the input and output tensors to uint8 (APIs added in r2.3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtflite_model_quant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     return super(TFLiteKerasModelConverterV2,\n\u001b[0;32m--> 831\u001b[0;31m                  self).convert(graph_def, input_tensors, output_tensors)\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[1;32m    636\u001b[0m         self.inference_input_type, self.inference_output_type)\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcalibrate_and_quantize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calibrate_quantize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_sparsify_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_calibrate_quantize_model\u001b[0;34m(self, result, inference_input_type, inference_output_type, activations_type, allow_float)\u001b[0m\n\u001b[1;32m    438\u001b[0m           self.representative_dataset)\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mcalibrate_quantize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_calibrator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalibrator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_calibrate_only\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_new_quantizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m       calibrated = calibrate_quantize.calibrate(\n",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.7/site-packages/tensorflow/lite/python/optimize/calibrator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_content)\u001b[0m\n\u001b[1;32m     52\u001b[0m           _calibration_wrapper.CalibrationWrapper(model_content))\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to parse the model: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calibrator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to parse the model.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to parse the model: pybind11::init(): factory function returned nullptr."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ai/anaconda3/envs/tf_2/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/ai/anaconda3/envs/tf_2/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp60c7cd8s/assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93728"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = '../ner_model_weight/model_conv.tflite'\n",
    "open(save_path,'wb').write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
